{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pandas 及应用\n",
        "\n",
        "Pandas是数据分析最常用的包:\n",
        "\n",
        "- Pandas 定义了处理数据的结构；\n",
        "- 数据处理：读取、调整指数、日期和时间序列、排序、分组、处理缺失值；\n",
        "- 一些更复杂的统计功能，如 statsmodels 和 scikit-learn，也是建立在pandas基础上。\n",
        "\n",
        "## Pandas 序列\n",
        "\n",
        "\n",
        "\n",
        "Pandas中两类数据，Series 和 DataFrame；\n",
        "\n",
        "Series 基于Numpy数组，支持许多类似运算；\n",
        "\n",
        "Series 可以看作一“列”数据；\n",
        "\n",
        "DataFrame 可以看作储存相应列数据的二维对象；类似Excel表单；\n",
        "\n",
        "Series一些方法\n"
      ],
      "id": "d44c3a4a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(123)\n",
        "s = pd.Series(np.random.randn(100), name=\"daily return\")\n",
        "s.plot();\n",
        "np.abs(s)\n",
        "s.describe()"
      ],
      "id": "53d2a88e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pandas数据框\n",
        "\n",
        "\n",
        "DataFrames 是几列数据组成，每一列对应一个变量；\n",
        "\n",
        "用来方便的处理行和列组织的数据；索引（index）对应行，变量列名（columns）对应列；\n",
        "\n",
        "可以读取各类软件格式存储数据，csv, excel, stata, html, json,sql等；\n",
        "\n",
        "\n",
        "## 应用：Penn World Table\n",
        "\n",
        "这一部分应用[Penn World Table](https://www.rug.nl/ggdc/productivity/pwt/)介绍对原始数据的一些常见处理方法。该数据集当前版本为PWT 10.01，包含183个国家1950-2019年的收入、产出、投入和生产率等指标，详细介绍可参见[User Guide to PWT 10.0 data files](https://www.rug.nl/ggdc/docs/pwt100-user-guide-to-data-files.pdf)。数据背后的方法、理论及使用建议，可参见 @feenstra2015next。\n",
        "\n",
        "网站提供了Stata和Excel格式数据，这里我们下载了后者。数据本身是一个面板数据（Panel Data），“国家 - 年” 唯一识别一个观测值。我们从截面数据入手先只保留2019年数据， 然后再看更复杂的情况。\n",
        "\n",
        "### 导入数据\n",
        "\n",
        "假设数据保存在当前路径的datasets子文件中：\n"
      ],
      "id": "eeae18e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "pwt = pd.read_excel(io = \"datasets/pwt1001.xlsx\",\n",
        "                header=0,                \n",
        "                sheet_name=\"Data\")\n",
        "# 保留2019年数据\n",
        "pwt2019 = pwt[pwt['year'] == 2019].copy().drop(labels='cor_exp',axis=1)"
      ],
      "id": "46bbf19d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意其中的几个参数，`io`是文件路径；`header`表明列标题行，这里是第一行；`sheet_name`是数据所在表单名；将载入的数据赋值给pwt数据框。我们只保留2019年的观测值，变量`cor_exp`在这一年全部为缺失值，这里直接删除了。\n",
        "\n",
        "先为`pwt2019`数据框设置索引变量，这里使用国家名代码变量（countrycode）：\n"
      ],
      "id": "b90cbf8c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.set_index('countrycode', inplace=True)"
      ],
      "id": "079d5221",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以`df.info()`概率数据集，或者使用`df.head()`或`df.tail()`查看头部和尾部观测值：\n"
      ],
      "id": "f081b7ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.info()\n",
        "pwt2019.head()"
      ],
      "id": "6c733f2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "默认显示5条观测值，如果希望看到更多观测值，可以使用 `df.tail(n=10)` 修改数值。\n",
        "\n",
        "可以应用`.shape, .ndim`,`.columns`等属性查看基本信息，可以看到数据集包含51个变量共183个观测值。\n"
      ],
      "id": "93d09ad8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pwt2019.shape)\n",
        "print(pwt2019.columns)"
      ],
      "id": "7126408a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 选择观测值和变量\n",
        "\n",
        "应用中经常对某些观测值或特定子集进行操作，因此很重要的一步是选择观测值和变量。\n",
        "\n",
        "最基本的方法可以通过Python数组的切片（slicing）方式选择特定的**行**。例如，选择第3至5个观测值：\n"
      ],
      "id": "85093d2f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019[2:5]"
      ],
      "id": "d182c618",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "要选择**列**，可以用包含列名字的列表：\n"
      ],
      "id": "74e44359"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vars_selected = ['country', 'rgdpe', 'rgdpo', 'pop', 'emp', 'cgdpe', 'cgdpo', 'ctfp' ]\n",
        "df = pwt2019[vars_selected]"
      ],
      "id": "0ce73493",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `.loc`方法\n",
        "\n",
        "`.loc` 是基于 标签（label-based） 的数据选择方法。这意味着你使用行和列的实际标签名来选择数据，而不是它们的整数位置。\n",
        "\n",
        "例如，要选择金砖国家（BRICKS）的观测值：\n"
      ],
      "id": "4151a206"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bricks = ['CHN', 'BRA', 'RUS', 'IND', 'ZAF']\n",
        "pwt2019.loc[bricks]"
      ],
      "id": "c91cdc71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "或者选择列：\n"
      ],
      "id": "4d16305e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "variables = ['country', 'rgdpe', 'pop']\n",
        "pwt2019.loc[:, variables]"
      ],
      "id": "23e67737",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "或者同时指定行和列：\n"
      ],
      "id": "e8f0b81e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.loc[bricks, variables]"
      ],
      "id": "8d43a043",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `.iloc`方法\n",
        "\n",
        "相应的，`.iloc` 是基于整数位置（integer-location based）的，使用行和列的整数位置（从 0 开始）来选择数据。例如：\n"
      ],
      "id": "9399ab9b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 选择第2行数据（索引位置为1）\n",
        "pwt2019.iloc[1]\n",
        "# 选择第1行（索引为0）、第3行（索引为2）和第5行（索引为4）\n",
        "pwt2019.iloc[[0, 2, 4]]\n",
        "# 选择前5行、第4至第6列观测值\n",
        "pwt2019.iloc[:5, 3:6]"
      ],
      "id": "37355021",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "这里需要注意Python中索引位置。Python中进行切片（slicing）操作时，语法通常类似 `[start:end]`，要注意：\n",
        "\n",
        "- `start`：切片的起始索引，对应的元素会被包含。\n",
        "- `end`：切片的结束索引，对应的元素不会被包含。\n",
        "  \n",
        "#### 根据条件筛选\n",
        "\n",
        "除了根据索引或位置选择数据外，也可以利用条件来筛选观测值。例如，根据人口变量（`pop`，单位：百万）选择2019年总人口超过2亿的观测值：\n"
      ],
      "id": "568e269b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019[pwt2019['pop'] >= 200]"
      ],
      "id": "e7181b3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，`pwt2019['pop'] >= 200` 的结果是一列布林值，然后`pwt2019[]`选择返回取值为`True`的观测值。\n",
        "\n",
        "再例如，下面的代码包含了两个条件：\n",
        "\n",
        "- 国家名属于金砖国家。注意这里使用了Pandas 中的`df.isin()`函数；\n",
        "- 2019年人口超过10亿。\n",
        "  \n",
        "当有不止一个条件时，我们用`&`, `|`表示`and` 和 `or`运算符；\n"
      ],
      "id": "b938915c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "BRICKS = ['China','Brazil',  ' Russian Federation', 'India', 'South Africa']\n",
        "#\n",
        "pwt2019[(pwt2019['country'].isin(BRICKS)) & (pwt2019['pop'] > 1000)]"
      ],
      "id": "5b1244aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "更复杂的情况，可以在条件语句中加入数学表达式。例如，下面的代码筛选了人均实际GDP超过2万美元和人口超过5000万的国家的观测值，这里人均实际GDP是购买力平价调整后支出法衡量的实际GDP与人口的比值：\n"
      ],
      "id": "30c3c9b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019[(pwt2019['rgdpe']/pwt2019['pop'] > 20000) & (pwt2019['pop'] > 50)]"
      ],
      "id": "2435fe3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### apply 方法\n",
        "\n",
        "Pandas中一个广泛应用的方法是 `df.apply()`，它将一个函数应用到每一行/列，返回一个序列；\n",
        "\n",
        "函数可以是内嵌的（built in）也可以是自定义的，例如，计算每一列的最大值，为了节省输出空间，使用子集`df`数据框：\n"
      ],
      "id": "bbe88a48"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.apply(np.max, axis=0)"
      ],
      "id": "16e43515",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "或者，自定义一个函数`range(x)`计算极差：\n"
      ],
      "id": "92e7a983"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "def range(x):\n",
        "    return np.max(x) - np.min(x)\n",
        "df.select_dtypes(np.number).apply(range)"
      ],
      "id": "8219e880",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "再例如，归一化（normalization）经常使用minmax方法：\n",
        "$$\n",
        "Y = \\frac{X_{i} - \\min(X_{i})}{\\max(X_{i}) - \\min(X_{i})}\n",
        "$$\n",
        "\n",
        "我们定义一个函数`minmax()`，然后应用`apply()`方法：\n"
      ],
      "id": "9415789e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def minmax(S):\n",
        "    return (S-S.min())/(S.max() - S.min())\n",
        "pwt2019[['pop','rgdpe', 'emp']].apply(minmax)"
      ],
      "id": "070c2dcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "经常将`lambda`函数方法与`df.apply()`方法相结合。例如，数据集中有4个指标度量GDP，分别是`['rgdpe', 'rgdpo','cgdpe','cgdpo']`，假设我们希望计算一个加权平均数，权重为（0.3，0.2，0.3，0.2）：\n"
      ],
      "id": "0b3381cf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "variables = ['rgdpe', 'rgdpo','cgdpe','cgdpo']\n",
        "df[variables].apply(lambda row:\n",
        "    row['rgdpe']*0.3 + row['rgdpo']*0.2 + row['cgdpe']*0.3 + row['cgdpo']*0.2,\n",
        "    axis=1)"
      ],
      "id": "28c5e4a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，z选项`axis = 1` ，将函数应用至每一行，默认值为0。\n",
        "\n",
        "\n",
        "### 检测和处理缺失值\n",
        "\n",
        "Pandas中最常用的缺失值表示是`NaN`（Not a Number）。可以使用`isnull()`或`isna()`函数检测缺失值，返回一个布尔型的DataFrame，其中`True`表示缺失值：\n"
      ],
      "id": "e2d9be15"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.isna()\n",
        "#pwt2019.isnull()"
      ],
      "id": "7b8536c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "下面的的代码计算了缺失值的数量，将其除以样本容量得到缺失值比例，然后按照降序排序，并将比例最高的前15个变量绘制柱形图：\n"
      ],
      "id": "d0a57e17"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "(pwt2019.isna().sum()/pwt2019.shape[0]*100).sort_values(ascending=False)[:15].plot(kind='bar', ax=ax)\n",
        "ax.set_ylabel(\"%\")\n",
        "plt.show()"
      ],
      "id": "0971611c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "另一种图示的方法是类似矩阵绘图的方式，将缺失值标记出来，`missingno`库有简单的命令实现：\n"
      ],
      "id": "cb4ee0f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import missingno as msno\n",
        "plt.figure(figsize=(12, 6))\n",
        "msno.matrix(pwt2019)\n",
        "plt.title(\"Missing Values Matrix\")\n",
        "plt.show()"
      ],
      "id": "868439c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**删除缺失值**\n",
        "\n",
        "处理缺失值的方法有很多种，选择哪种方法取决于你的数据特性、缺失原因以及分析目标。最直接的方法是使用`df.dropna()`函数删除包含缺失值的行或列：\n"
      ],
      "id": "85cfa8d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 删除含缺失值的行\n",
        "pwt2019.dropna()\n",
        "# 删除含缺失值的列\n",
        "pwt2019.dropna(axis=1)"
      ],
      "id": "f888fad3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "另外，上面的命令并没有改变原数据框，可以通过赋值方式保存。或者加上选项`df.dropna(inplace=True)`，即在原数据框中生效。\n",
        "\n",
        "**填充**\n",
        "\n",
        "`df.fillna()`是用于填充缺失值的核心函数。\n"
      ],
      "id": "854fa6af"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#\n",
        "pwt2019.fillna(0)\n",
        "#\n",
        "pwt2019.select_dtypes(np.number).fillna(0).combine_first(pwt2019)\n",
        "pwt2019.select_dtypes(np.number).fillna(pwt2019.mean(numeric_only=True)).combine_first(pwt2019)\n",
        "pwt2019.select_dtypes(np.number).fillna(pwt2019.median(numeric_only=True)).combine_first(pwt2019)"
      ],
      "id": "30a0981c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#pwt2019.fillna(method='ffill')\n",
        "pwt2019.fillna(method='bfill')"
      ],
      "id": "c3607ff0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**插值法（Interpolation）**\n",
        "\n",
        "除了填充给定值以外，也有更复杂的插值法。\n"
      ],
      "id": "37e87995"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.interpolate(method=\"linear\")"
      ],
      "id": "3aefc08f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "更复杂的方法涉及到模型估计问题，如KNN预测等。Scikit-learn库有专门的方法，这里就不多涉及。\n"
      ],
      "id": "2ceed1b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer_mean = SimpleImputer(strategy='mean')\n",
        "pd.DataFrame(imputer_mean.fit_transform(pwt2019.select_dtypes(np.number)), columns=pwt2019.select_dtypes(np.number).columns)"
      ],
      "id": "0482a955",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 缩尾处理\n",
        "\n",
        "应用中，常需要对异常值进行一定的处理，其中一种方法是缩尾处理（Winsorize），将极端值替换为某个百分位数的值，例如，将上限设为 99 百分位数，下限设为 1 百分位数。\n",
        "\n",
        "可以使用`df.clip()`函数实现，例如全要素生产率水平`ctfp`：\n"
      ],
      "id": "972b2e2b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "q95 = pwt2019['ctfp'].quantile(0.95)\n",
        "q05 = pwt2019['ctfp'].quantile(0.05)\n",
        "\n",
        "pwt2019['ctfp'].dropna().clip(lower=q05, upper=q95, inplace=False)"
      ],
      "id": "f46799f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 观测值排序\n",
        "\n",
        "有时候需要对数据集进行一定的排序，Pandas中可以按索引(`df.sort_index`)和值（`df.sort_values`）排序。\n",
        "\n",
        "例如，将索引按降序排序，这里的索引是国家代码，因此升序/降序是按照字母顺序：\n"
      ],
      "id": "5db9bea5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019.sort_index(ascending=False)"
      ],
      "id": "aa6f3833",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "来看`df.sort_values`的例子，假设我们希望按2019年的人均GDP（PPP链式调整后）降序排列：\n"
      ],
      "id": "c91626b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt2019['rgdp_per'] = pwt2019['rgdpe']/pwt2019['pop']\n",
        "pwt2019.sort_values(by='rgdp_per', ascending=False) "
      ],
      "id": "b233ecb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 数据集合并\n",
        "\n",
        "实际应用中，数据可能来自不同的来源，经常需要合并数据集，`pd.merge()`函数\n"
      ],
      "id": "8590fe1d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import wbgapi as wb\n",
        "inf = wb.data.DataFrame(series='NY.GDP.DEFL.KD.ZG', time='2019')\n",
        "pd.merge(df[['country','pop','emp']], inf, left_index=True, right_index=True)"
      ],
      "id": "e5034ad3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 多级索引\n",
        "\n",
        "这里的数据是一个面板数据，“国家-年”对应一个观测值，可以利用Pandas的多级索引功能，详见Pandas文档[MultiIndex / advanced indexing](https://pandas.pydata.org/docs/dev/user_guide/advanced.html#)。\n"
      ],
      "id": "97a01f24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt = pd.read_excel(io = \"datasets/pwt1001.xlsx\",\n",
        "                header=0,                \n",
        "                sheet_name=\"Data\")\n",
        "pwt.set_index(['countrycode','year'], inplace=True)"
      ],
      "id": "bfd8c763",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以使用`.loc()`方法选择需要的数据，例如：\n"
      ],
      "id": "cfd0d188"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 中国子集\n",
        "df_china = pwt.loc['CHN']\n",
        "# 中国、美国子集\n",
        "df_china_us = pwt.loc[['CHN','USA']]\n",
        "# 变量子集\n",
        "df_sub_china_us = pwt.loc[['CHN', 'USA']][['rgdpe','rgdpo']]"
      ],
      "id": "3e1d4eb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "如果需要选择某一年的截面数据：\n"
      ],
      "id": "dea05fdf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.loc[(slice(None), [2019]), :]\n",
        "# 1992年之后的数据\n",
        "pwt.loc[(slice(None), slice(1992, None)), :]"
      ],
      "id": "183aa254",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "这里使用了`df.loc`结合`slice`函数的方法，注意：\n",
        "\n",
        "- `slice(None)`: 这表示选择 所有 `countrycode`。\n",
        "- `slice(1992, None)`: 这表示从 `year` 的 1992年 开始，选择到 **所有**后续年份。由于索引是排序的（通常情况下），这有效地选择了所有 `year > 1992` 的数据。\n",
        "- `:`表示选择所有列。\n",
        "\n",
        "上面的例子使用`slice`函数不是那么直观，也可以使用`df.index.get_level_values('year')`提取索引`year`的值，形成一个序列（可以另存为一个变量），然后利用表达式生成一个布尔序列，对数据框进行筛选：\n"
      ],
      "id": "76295af3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt[pwt.index.get_level_values('year') > 1992]"
      ],
      "id": "23082748",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "当然，可以同时选择指定的变量和年份，例如：\n"
      ],
      "id": "629f8da2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.loc[(slice(None),[2016,2019]), ['rgdpe','rgdpo']]\n",
        "#\n",
        "pwt.loc[(([\"CHN\", \"USA\"], [2016,2019])), ['rgdpe','rgdpo']]"
      ],
      "id": "d29eb5f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "除了通常的排序以外，由于有了二级索引，如果按索引排序，两级索引变量是同时排序的：\n"
      ],
      "id": "6dab069b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.sort_index()"
      ],
      "id": "f7e978ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以对两级索引以列表的形式分别设定排序的顺序。例如，先将国家代码按字母升序，然后将年降序：\n"
      ],
      "id": "dd72a027"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.sort_index(ascending=[True, False])"
      ],
      "id": "cdda70c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `stack` 和 `unstack`\n",
        "\n",
        "数据有“长（long）”和“宽（wide）”两种组织方式，Penn World Table 是以“长”的形式保存的。有时候需要在两种数据格式之间进行转换，就需要用到`df.stack()`和`df.unstack()`函数。\n",
        "\n",
        "注意，`df.unstack()`函数的参数`level=`，设置为哪一级索引，便生成为列。默认在最后一级索引上转换，即年，因此列便为年，行为国家，反之，列为国家，行为年。如下面例子所示，为了简便只保留了三个国家5年的数据：\n"
      ],
      "id": "d9df9a91"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt_sub = pwt.loc[([\"CHN\", \"KOR\", \"USA\"], slice(2015, None)), [\"rgdpe\", \"pop\"]]\n",
        "# \n",
        "pwt_sub_wide = pwt_sub.unstack(level=-1)\n",
        "# pwt_sub.unstack(level=0)"
      ],
      "id": "d7e20501",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "要获得长格式的数据，使用`df.stack()`即可：\n"
      ],
      "id": "a4345f29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt_sub_wide.stack(future_stack=True)"
      ],
      "id": "9eb75b31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "当我们从一些数据库下载数据时，常见形式为列为不同时期相同变量的值。例如，从世界银行下载人均GDP和人口数据：\n"
      ],
      "id": "56a8d7e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import wbgapi as wb\n",
        "df = wb.data.DataFrame(series=['NY.GDP.PCAP.CD', \"SP.POP.TOTL\"], \n",
        "                                #time=range(2017,2020),\n",
        "                                time=['YR2017','YR2018','YR2019'],\n",
        "                                 numericTimeKeys=True)\n",
        "df.head()"
      ],
      "id": "467a6711",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "下载的数据`df`索引是“economy - series”，每一年数据一列。我们希望序列成为列变量，时间成为索引。我们可以先对数据进行转置成宽格式的数据，然后再在国家层面堆叠，使其成为索引，再交换索引排序得到通常的情况：\n"
      ],
      "id": "b70f7b0f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.T.stack(level=0, future_stack=True).swaplevel().sort_index()"
      ],
      "id": "6e644cab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "另外，stack不是唯一的方法，也可以使用`df.melt()`结合`df.pivot_table()`函数来实现：\n"
      ],
      "id": "38f37cf5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_reset = df.reset_index()\n",
        "df_long = df_reset.melt(id_vars=['economy', 'series'], var_name='year', value_name='value')\n",
        "df_long.pivot_table(index=['economy', 'year'], columns='series', values='value')"
      ],
      "id": "ec3a4802",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pandas中的分组计算（`groupby`）\n",
        "\n",
        "Pandas 的分组（`groupby()`）方法按照“分割-应用-组合（split-apply-combine）”的原理，创建一个 groupby 对象，可以应用各种方法来聚合、转换或过滤数据。更多介绍参见Pandas官方文档[Group by: split-apply-combine](https://pandas.pydata.org/docs/user_guide/groupby.html)。\n",
        "\n",
        "选择合适的方法：\n",
        "\n",
        "- 如果你的操作只是简单的统计（如求和、平均值），优先使用聚合方法，它们通常效率最高。\n",
        "- 如果需要返回与原始 DataFrame 相同长度的结果，例如进行组内标准化，使用转换方法。\n",
        "- 如果需要根据组的属性来决定保留或丢弃整个组，使用过滤方法。\n",
        "- 当以上方法都无法满足需求时，或者需要执行更复杂的自定义逻辑时，使用**apply()**方法。\n",
        "\n",
        "#### 聚合方法（Aggregation Methods）\n",
        "\n",
        "聚合方法将每个组的数据压缩成一个单一的值，是最常用的`groupby`操作，例如`mean()`,`sum()`,`count()`,`size()`,`min()`,`max()`,`std()`,`var()`,`median()`等常见的统计量，或者`first()`,`last()`,`nth(n)`等获取第一个、最好一个或第n个值：\n",
        "\n",
        "\n",
        "**索引**\n",
        "\n",
        "例如，根据索引计算世界人口，先在索引上分组，然后使用`.sum()`函数：\n"
      ],
      "id": "a6de773f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.groupby(level=1)['pop'].sum()"
      ],
      "id": "2319c328",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`avh`变量度量了“Average annual hours worked by persons engaged”,让我们分组计算平均，得到按年和按国家平均\n"
      ],
      "id": "62797fc0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avh = pwt[pwt['avh'].notna()]\n",
        "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
        "avh.groupby(level=1)['avh'].mean().sort_values(ascending=False).plot(kind='line', ax=ax[0])\n",
        "ax[0].set_xlabel(\"\")\n",
        "ax[0].set_ylabel(\"Average annual hours worked by persons engaged\")\n",
        "avh.groupby(level=0)['avh'].mean().sort_values(ascending=False)[:25].plot(kind='bar', ax=ax[1])\n",
        "ax[1].set_xlabel(\"\")\n",
        "ax[1].set_ylabel(\"Average annual hours worked by persons engaged\")\n",
        "plt.show()"
      ],
      "id": "24f93d21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最常见的是按变量进行分组，例如，按国家名`country`分组，最后一个观测值：\n"
      ],
      "id": "b4d57b53"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.groupby(by=['country']).last()"
      ],
      "id": "c4941823",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 转换方法（Transformation Methods）\n",
        "\n",
        "- `transform(func)`: 对每个组应用函数，并将结果广播回原始 DataFrame 的形状。\n",
        "- `rank(method='average')`: 计算组内排名。\n",
        "- `fillna(value)`: 在组内填充缺失值。\n"
      ],
      "id": "a25c9a2e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avh.groupby(level=1)['avh'].transform('mean')\n",
        "avh.groupby(level=1)['avh'].mean()"
      ],
      "id": "c17b25d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "注意，转换与聚合的区别,转换将生成的值与原数据观测值一样多，这里是3492个，而聚合只有70个。\n",
        "\n",
        "`.transform()`方法可以与`lambda`函数相结合，例如：\n"
      ],
      "id": "e12851fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.select_dtypes(np.number).groupby(level=0).transform(lambda x: (x - x.mean())/x.std())"
      ],
      "id": "5945f527",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 过滤方法（Filtration Methods）\n",
        "\n",
        "过滤方法会根据每个组的某个条件来排除整个组。\n",
        "\n",
        "- filter(func): 根据一个返回布尔值的函数来过滤组。如果函数对一个组返回 True，则保留该组；否则，删除该组。\n"
      ],
      "id": "e61a0539"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pwt.groupby(level=0).filter(lambda x: x['pop'].mean() > 50)"
      ],
      "id": "600f7025",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 应用方法（Application Methods）\n",
        "apply() 方法是最通用的方法，它允许你对每个组应用任何自定义函数。这个函数可以执行聚合、转换或过滤操作，或者任何更复杂的逻辑。\n",
        "\n",
        "- apply(func): 将一个自定义函数应用于每个组。函数的返回值可以是 Series、DataFrame 或标量。\n"
      ],
      "id": "d6611965"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}